{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "E5pj7igw0tKd"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "fighter_stats = pd.read_csv(\"fighter_stats.csv\")\n",
        "large_dataset = pd.read_csv(\"large_dataset.csv\")"
      ],
      "metadata": {
        "id": "suZ4vGzH0vli"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "# Drop rows with missing 'name' in fighter_stats\n",
        "fighter_stats = fighter_stats.dropna(subset=[\"name\"])\n",
        "\n",
        "# Fill missing numeric columns with mean, categorical with mode\n",
        "numeric_columns_fighter_stats = fighter_stats.select_dtypes(include=[np.number]).columns\n",
        "fighter_stats[numeric_columns_fighter_stats] = fighter_stats[numeric_columns_fighter_stats].fillna(\n",
        "    fighter_stats[numeric_columns_fighter_stats].mean()\n",
        ")\n",
        "\n",
        "numeric_columns_large_dataset = large_dataset.select_dtypes(include=[np.number]).columns\n",
        "categorical_columns_large_dataset = large_dataset.select_dtypes(exclude=[np.number]).columns\n",
        "large_dataset[numeric_columns_large_dataset] = large_dataset[numeric_columns_large_dataset].fillna(\n",
        "    large_dataset[numeric_columns_large_dataset].mean()\n",
        ")\n",
        "for column in categorical_columns_large_dataset:\n",
        "    large_dataset[column] = large_dataset[column].fillna(large_dataset[column].mode()[0])"
      ],
      "metadata": {
        "id": "-yd0abe_07Xv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical features (e.g., stances)\n",
        "stance_map = {stance: idx for idx, stance in enumerate(large_dataset[\"r_stance\"].unique(), start=1)}\n",
        "large_dataset[\"r_stance\"] = large_dataset[\"r_stance\"].map(stance_map)\n",
        "large_dataset[\"b_stance\"] = large_dataset[\"b_stance\"].map(stance_map)"
      ],
      "metadata": {
        "id": "nuLT5Lb41HQD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and labels for evaluation\n",
        "feature_sets = {\n",
        "    \"selected_features\": [\n",
        "        \"height_diff\", \"weight_diff\", \"reach_diff\",\n",
        "        \"r_stance\", \"b_stance\"\n",
        "    ],\n",
        "    \"all_features\": [\n",
        "        \"age_diff\", \"height_diff\", \"weight_diff\", \"reach_diff\",\n",
        "        \"SLpM_total_diff\", \"SApM_total_diff\", \"sig_str_acc_total_diff\",\n",
        "        \"td_acc_total_diff\", \"str_def_total_diff\", \"td_def_total_diff\",\n",
        "        \"sub_avg_diff\", \"td_avg_diff\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Define the target variable\n",
        "y = large_dataset[\"winner\"].apply(lambda x: 1 if x == \"Red\" else 0)"
      ],
      "metadata": {
        "id": "nuH-_NSC1MG3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models\n",
        "models = {\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=50, random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=50, random_state=42),\n",
        "    \"SVM\": SVC(max_iter=50, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(n_estimators=50, use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "S6NFsnsG2ZdJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define split ratios\n",
        "split_ratios = [(0.8, 0.1, 0.1), (0.6, 0.3, 0.1), (0.6, 0.2, 0.2)]"
      ],
      "metadata": {
        "id": "wm3sk1ZN2cx3"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define mapping for standardizing weight classes\n",
        "weight_class_mapping = {\n",
        "    \"UFC Women's Flyweight Title\": \"Women's Flyweight\",\n",
        "    \"UFC Women's Strawweight Title\": \"Women's Strawweight\",\n",
        "    \"UFC Women's Bantamweight Title\": \"Women's Bantamweight\",\n",
        "    \"UFC Flyweight Title\": \"Flyweight\",\n",
        "    \"UFC Bantamweight Title\": \"Bantamweight\",\n",
        "    \"UFC Featherweight Title\": \"Featherweight\",\n",
        "    \"UFC Lightweight Title\": \"Lightweight\",\n",
        "    \"UFC Welterweight Title\": \"Welterweight\",\n",
        "    \"UFC Middleweight Title\": \"Middleweight\",\n",
        "    \"UFC Light Heavyweight Title\": \"Light Heavyweight\",\n",
        "    \"UFC Heavyweight Title\": \"Heavyweight\"\n",
        "}\n",
        "\n",
        "# Standardize weight_class column\n",
        "large_dataset[\"weight_class\"] = large_dataset[\"weight_class\"].replace(weight_class_mapping)"
      ],
      "metadata": {
        "id": "GMoWQ_KQGUra"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by weight class\n",
        "weight_classes = large_dataset[\"weight_class\"].unique()\n",
        "results = []\n",
        "\n",
        "# Loop through each weight class\n",
        "for weight_class in weight_classes:\n",
        "    subset = large_dataset[large_dataset[\"weight_class\"] == weight_class]\n",
        "    if len(subset) < 10:  # Skip classes with fewer than 10 fights\n",
        "        continue\n",
        "\n",
        "    y = subset[\"winner\"].apply(lambda x: 1 if x == \"Red\" else 0)\n",
        "    for feature_set_name, features in feature_sets.items():\n",
        "        X = subset[features].dropna()\n",
        "        for train_ratio, valid_ratio, test_ratio in split_ratios:\n",
        "            # Calculate split indices\n",
        "            total_len = len(X)\n",
        "            train_end = int(total_len * train_ratio)\n",
        "            valid_end = train_end + int(total_len * valid_ratio)\n",
        "\n",
        "            # Split the data\n",
        "            X_train = X.iloc[:train_end]\n",
        "            y_train = y.iloc[:train_end]\n",
        "\n",
        "            X_valid = X.iloc[train_end:valid_end]\n",
        "            y_valid = y.iloc[train_end:valid_end]\n",
        "\n",
        "            X_test = X.iloc[valid_end:]\n",
        "            y_test = y.iloc[valid_end:]\n",
        "\n",
        "            # Skip if y_train contains only one class\n",
        "            if len(y_train.unique()) < 2:\n",
        "                print(f\"Skipping weight class '{weight_class}' due to single-class training data.\")\n",
        "                continue\n",
        "\n",
        "            # Train models and evaluate\n",
        "            for model_name, model in models.items():\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred_test = model.predict(X_test)\n",
        "                y_pred_valid = model.predict(X_valid)\n",
        "                test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "                test_f1 = f1_score(y_test, y_pred_test)\n",
        "                valid_accuracy = accuracy_score(y_valid, y_pred_valid)\n",
        "                valid_f1 = f1_score(y_valid, y_pred_valid)\n",
        "\n",
        "                results.append({\n",
        "                    \"Weight Class\": weight_class,\n",
        "                    \"Feature Set\": feature_set_name,\n",
        "                    \"Model\": model_name,\n",
        "                    \"Split Ratio\": f\"{int(train_ratio*10)}:{int(valid_ratio*10)}:{int(test_ratio*10)}\",\n",
        "                    \"Validation Accuracy\": valid_accuracy,\n",
        "                    \"Validation F1\": valid_f1,\n",
        "                    \"Test Accuracy\": test_accuracy,\n",
        "                    \"Test F1\": test_f1\n",
        "                })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BBM-CL32gcM",
        "outputId": "f586fd24-384d-45e5-fd0c-ced69820bb65"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:26:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:26:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:26:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:26:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:26:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:26:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:26:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:26:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:26:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:26:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:27:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping weight class 'Open Weight' due to single-class training data.\n",
            "Skipping weight class 'Open Weight' due to single-class training data.\n",
            "Skipping weight class 'Open Weight' due to single-class training data.\n",
            "Skipping weight class 'Open Weight' due to single-class training data.\n",
            "Skipping weight class 'Open Weight' due to single-class training data.\n",
            "Skipping weight class 'Open Weight' due to single-class training data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to DataFrame and display\n",
        "results_df = pd.DataFrame(results)\n",
        "# Set pandas options to display all rows and columns\n",
        "pd.set_option('display.max_rows', None)  # Show all rows\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n",
        "\n",
        "# Print the entire DataFrame\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m403ZH7E7oDM",
        "outputId": "6358ba2e-395e-4f67-9f35-ad215efc5107"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Weight Class        Feature Set               Model Split Ratio  \\\n",
            "0        Women's Flyweight  selected_features        RandomForest       8:1:1   \n",
            "1        Women's Flyweight  selected_features  LogisticRegression       8:1:1   \n",
            "2        Women's Flyweight  selected_features                 SVM       8:1:1   \n",
            "3        Women's Flyweight  selected_features             XGBoost       8:1:1   \n",
            "4        Women's Flyweight  selected_features        RandomForest       6:3:1   \n",
            "5        Women's Flyweight  selected_features  LogisticRegression       6:3:1   \n",
            "6        Women's Flyweight  selected_features                 SVM       6:3:1   \n",
            "7        Women's Flyweight  selected_features             XGBoost       6:3:1   \n",
            "8        Women's Flyweight  selected_features        RandomForest       6:2:2   \n",
            "9        Women's Flyweight  selected_features  LogisticRegression       6:2:2   \n",
            "10       Women's Flyweight  selected_features                 SVM       6:2:2   \n",
            "11       Women's Flyweight  selected_features             XGBoost       6:2:2   \n",
            "12       Women's Flyweight       all_features        RandomForest       8:1:1   \n",
            "13       Women's Flyweight       all_features  LogisticRegression       8:1:1   \n",
            "14       Women's Flyweight       all_features                 SVM       8:1:1   \n",
            "15       Women's Flyweight       all_features             XGBoost       8:1:1   \n",
            "16       Women's Flyweight       all_features        RandomForest       6:3:1   \n",
            "17       Women's Flyweight       all_features  LogisticRegression       6:3:1   \n",
            "18       Women's Flyweight       all_features                 SVM       6:3:1   \n",
            "19       Women's Flyweight       all_features             XGBoost       6:3:1   \n",
            "20       Women's Flyweight       all_features        RandomForest       6:2:2   \n",
            "21       Women's Flyweight       all_features  LogisticRegression       6:2:2   \n",
            "22       Women's Flyweight       all_features                 SVM       6:2:2   \n",
            "23       Women's Flyweight       all_features             XGBoost       6:2:2   \n",
            "24             Heavyweight  selected_features        RandomForest       8:1:1   \n",
            "25             Heavyweight  selected_features  LogisticRegression       8:1:1   \n",
            "26             Heavyweight  selected_features                 SVM       8:1:1   \n",
            "27             Heavyweight  selected_features             XGBoost       8:1:1   \n",
            "28             Heavyweight  selected_features        RandomForest       6:3:1   \n",
            "29             Heavyweight  selected_features  LogisticRegression       6:3:1   \n",
            "30             Heavyweight  selected_features                 SVM       6:3:1   \n",
            "31             Heavyweight  selected_features             XGBoost       6:3:1   \n",
            "32             Heavyweight  selected_features        RandomForest       6:2:2   \n",
            "33             Heavyweight  selected_features  LogisticRegression       6:2:2   \n",
            "34             Heavyweight  selected_features                 SVM       6:2:2   \n",
            "35             Heavyweight  selected_features             XGBoost       6:2:2   \n",
            "36             Heavyweight       all_features        RandomForest       8:1:1   \n",
            "37             Heavyweight       all_features  LogisticRegression       8:1:1   \n",
            "38             Heavyweight       all_features                 SVM       8:1:1   \n",
            "39             Heavyweight       all_features             XGBoost       8:1:1   \n",
            "40             Heavyweight       all_features        RandomForest       6:3:1   \n",
            "41             Heavyweight       all_features  LogisticRegression       6:3:1   \n",
            "42             Heavyweight       all_features                 SVM       6:3:1   \n",
            "43             Heavyweight       all_features             XGBoost       6:3:1   \n",
            "44             Heavyweight       all_features        RandomForest       6:2:2   \n",
            "45             Heavyweight       all_features  LogisticRegression       6:2:2   \n",
            "46             Heavyweight       all_features                 SVM       6:2:2   \n",
            "47             Heavyweight       all_features             XGBoost       6:2:2   \n",
            "48            Middleweight  selected_features        RandomForest       8:1:1   \n",
            "49            Middleweight  selected_features  LogisticRegression       8:1:1   \n",
            "50            Middleweight  selected_features                 SVM       8:1:1   \n",
            "51            Middleweight  selected_features             XGBoost       8:1:1   \n",
            "52            Middleweight  selected_features        RandomForest       6:3:1   \n",
            "53            Middleweight  selected_features  LogisticRegression       6:3:1   \n",
            "54            Middleweight  selected_features                 SVM       6:3:1   \n",
            "55            Middleweight  selected_features             XGBoost       6:3:1   \n",
            "56            Middleweight  selected_features        RandomForest       6:2:2   \n",
            "57            Middleweight  selected_features  LogisticRegression       6:2:2   \n",
            "58            Middleweight  selected_features                 SVM       6:2:2   \n",
            "59            Middleweight  selected_features             XGBoost       6:2:2   \n",
            "60            Middleweight       all_features        RandomForest       8:1:1   \n",
            "61            Middleweight       all_features  LogisticRegression       8:1:1   \n",
            "62            Middleweight       all_features                 SVM       8:1:1   \n",
            "63            Middleweight       all_features             XGBoost       8:1:1   \n",
            "64            Middleweight       all_features        RandomForest       6:3:1   \n",
            "65            Middleweight       all_features  LogisticRegression       6:3:1   \n",
            "66            Middleweight       all_features                 SVM       6:3:1   \n",
            "67            Middleweight       all_features             XGBoost       6:3:1   \n",
            "68            Middleweight       all_features        RandomForest       6:2:2   \n",
            "69            Middleweight       all_features  LogisticRegression       6:2:2   \n",
            "70            Middleweight       all_features                 SVM       6:2:2   \n",
            "71            Middleweight       all_features             XGBoost       6:2:2   \n",
            "72            Bantamweight  selected_features        RandomForest       8:1:1   \n",
            "73            Bantamweight  selected_features  LogisticRegression       8:1:1   \n",
            "74            Bantamweight  selected_features                 SVM       8:1:1   \n",
            "75            Bantamweight  selected_features             XGBoost       8:1:1   \n",
            "76            Bantamweight  selected_features        RandomForest       6:3:1   \n",
            "77            Bantamweight  selected_features  LogisticRegression       6:3:1   \n",
            "78            Bantamweight  selected_features                 SVM       6:3:1   \n",
            "79            Bantamweight  selected_features             XGBoost       6:3:1   \n",
            "80            Bantamweight  selected_features        RandomForest       6:2:2   \n",
            "81            Bantamweight  selected_features  LogisticRegression       6:2:2   \n",
            "82            Bantamweight  selected_features                 SVM       6:2:2   \n",
            "83            Bantamweight  selected_features             XGBoost       6:2:2   \n",
            "84            Bantamweight       all_features        RandomForest       8:1:1   \n",
            "85            Bantamweight       all_features  LogisticRegression       8:1:1   \n",
            "86            Bantamweight       all_features                 SVM       8:1:1   \n",
            "87            Bantamweight       all_features             XGBoost       8:1:1   \n",
            "88            Bantamweight       all_features        RandomForest       6:3:1   \n",
            "89            Bantamweight       all_features  LogisticRegression       6:3:1   \n",
            "90            Bantamweight       all_features                 SVM       6:3:1   \n",
            "91            Bantamweight       all_features             XGBoost       6:3:1   \n",
            "92            Bantamweight       all_features        RandomForest       6:2:2   \n",
            "93            Bantamweight       all_features  LogisticRegression       6:2:2   \n",
            "94            Bantamweight       all_features                 SVM       6:2:2   \n",
            "95            Bantamweight       all_features             XGBoost       6:2:2   \n",
            "96           Featherweight  selected_features        RandomForest       8:1:1   \n",
            "97           Featherweight  selected_features  LogisticRegression       8:1:1   \n",
            "98           Featherweight  selected_features                 SVM       8:1:1   \n",
            "99           Featherweight  selected_features             XGBoost       8:1:1   \n",
            "100          Featherweight  selected_features        RandomForest       6:3:1   \n",
            "101          Featherweight  selected_features  LogisticRegression       6:3:1   \n",
            "102          Featherweight  selected_features                 SVM       6:3:1   \n",
            "103          Featherweight  selected_features             XGBoost       6:3:1   \n",
            "104          Featherweight  selected_features        RandomForest       6:2:2   \n",
            "105          Featherweight  selected_features  LogisticRegression       6:2:2   \n",
            "106          Featherweight  selected_features                 SVM       6:2:2   \n",
            "107          Featherweight  selected_features             XGBoost       6:2:2   \n",
            "108          Featherweight       all_features        RandomForest       8:1:1   \n",
            "109          Featherweight       all_features  LogisticRegression       8:1:1   \n",
            "110          Featherweight       all_features                 SVM       8:1:1   \n",
            "111          Featherweight       all_features             XGBoost       8:1:1   \n",
            "112          Featherweight       all_features        RandomForest       6:3:1   \n",
            "113          Featherweight       all_features  LogisticRegression       6:3:1   \n",
            "114          Featherweight       all_features                 SVM       6:3:1   \n",
            "115          Featherweight       all_features             XGBoost       6:3:1   \n",
            "116          Featherweight       all_features        RandomForest       6:2:2   \n",
            "117          Featherweight       all_features  LogisticRegression       6:2:2   \n",
            "118          Featherweight       all_features                 SVM       6:2:2   \n",
            "119          Featherweight       all_features             XGBoost       6:2:2   \n",
            "120            Lightweight  selected_features        RandomForest       8:1:1   \n",
            "121            Lightweight  selected_features  LogisticRegression       8:1:1   \n",
            "122            Lightweight  selected_features                 SVM       8:1:1   \n",
            "123            Lightweight  selected_features             XGBoost       8:1:1   \n",
            "124            Lightweight  selected_features        RandomForest       6:3:1   \n",
            "125            Lightweight  selected_features  LogisticRegression       6:3:1   \n",
            "126            Lightweight  selected_features                 SVM       6:3:1   \n",
            "127            Lightweight  selected_features             XGBoost       6:3:1   \n",
            "128            Lightweight  selected_features        RandomForest       6:2:2   \n",
            "129            Lightweight  selected_features  LogisticRegression       6:2:2   \n",
            "130            Lightweight  selected_features                 SVM       6:2:2   \n",
            "131            Lightweight  selected_features             XGBoost       6:2:2   \n",
            "132            Lightweight       all_features        RandomForest       8:1:1   \n",
            "133            Lightweight       all_features  LogisticRegression       8:1:1   \n",
            "134            Lightweight       all_features                 SVM       8:1:1   \n",
            "135            Lightweight       all_features             XGBoost       8:1:1   \n",
            "136            Lightweight       all_features        RandomForest       6:3:1   \n",
            "137            Lightweight       all_features  LogisticRegression       6:3:1   \n",
            "138            Lightweight       all_features                 SVM       6:3:1   \n",
            "139            Lightweight       all_features             XGBoost       6:3:1   \n",
            "140            Lightweight       all_features        RandomForest       6:2:2   \n",
            "141            Lightweight       all_features  LogisticRegression       6:2:2   \n",
            "142            Lightweight       all_features                 SVM       6:2:2   \n",
            "143            Lightweight       all_features             XGBoost       6:2:2   \n",
            "144   Women's Bantamweight  selected_features        RandomForest       8:1:1   \n",
            "145   Women's Bantamweight  selected_features  LogisticRegression       8:1:1   \n",
            "146   Women's Bantamweight  selected_features                 SVM       8:1:1   \n",
            "147   Women's Bantamweight  selected_features             XGBoost       8:1:1   \n",
            "148   Women's Bantamweight  selected_features        RandomForest       6:3:1   \n",
            "149   Women's Bantamweight  selected_features  LogisticRegression       6:3:1   \n",
            "150   Women's Bantamweight  selected_features                 SVM       6:3:1   \n",
            "151   Women's Bantamweight  selected_features             XGBoost       6:3:1   \n",
            "152   Women's Bantamweight  selected_features        RandomForest       6:2:2   \n",
            "153   Women's Bantamweight  selected_features  LogisticRegression       6:2:2   \n",
            "154   Women's Bantamweight  selected_features                 SVM       6:2:2   \n",
            "155   Women's Bantamweight  selected_features             XGBoost       6:2:2   \n",
            "156   Women's Bantamweight       all_features        RandomForest       8:1:1   \n",
            "157   Women's Bantamweight       all_features  LogisticRegression       8:1:1   \n",
            "158   Women's Bantamweight       all_features                 SVM       8:1:1   \n",
            "159   Women's Bantamweight       all_features             XGBoost       8:1:1   \n",
            "160   Women's Bantamweight       all_features        RandomForest       6:3:1   \n",
            "161   Women's Bantamweight       all_features  LogisticRegression       6:3:1   \n",
            "162   Women's Bantamweight       all_features                 SVM       6:3:1   \n",
            "163   Women's Bantamweight       all_features             XGBoost       6:3:1   \n",
            "164   Women's Bantamweight       all_features        RandomForest       6:2:2   \n",
            "165   Women's Bantamweight       all_features  LogisticRegression       6:2:2   \n",
            "166   Women's Bantamweight       all_features                 SVM       6:2:2   \n",
            "167   Women's Bantamweight       all_features             XGBoost       6:2:2   \n",
            "168              Flyweight  selected_features        RandomForest       8:1:1   \n",
            "169              Flyweight  selected_features  LogisticRegression       8:1:1   \n",
            "170              Flyweight  selected_features                 SVM       8:1:1   \n",
            "171              Flyweight  selected_features             XGBoost       8:1:1   \n",
            "172              Flyweight  selected_features        RandomForest       6:3:1   \n",
            "173              Flyweight  selected_features  LogisticRegression       6:3:1   \n",
            "174              Flyweight  selected_features                 SVM       6:3:1   \n",
            "175              Flyweight  selected_features             XGBoost       6:3:1   \n",
            "176              Flyweight  selected_features        RandomForest       6:2:2   \n",
            "177              Flyweight  selected_features  LogisticRegression       6:2:2   \n",
            "178              Flyweight  selected_features                 SVM       6:2:2   \n",
            "179              Flyweight  selected_features             XGBoost       6:2:2   \n",
            "180              Flyweight       all_features        RandomForest       8:1:1   \n",
            "181              Flyweight       all_features  LogisticRegression       8:1:1   \n",
            "182              Flyweight       all_features                 SVM       8:1:1   \n",
            "183              Flyweight       all_features             XGBoost       8:1:1   \n",
            "184              Flyweight       all_features        RandomForest       6:3:1   \n",
            "185              Flyweight       all_features  LogisticRegression       6:3:1   \n",
            "186              Flyweight       all_features                 SVM       6:3:1   \n",
            "187              Flyweight       all_features             XGBoost       6:3:1   \n",
            "188              Flyweight       all_features        RandomForest       6:2:2   \n",
            "189              Flyweight       all_features  LogisticRegression       6:2:2   \n",
            "190              Flyweight       all_features                 SVM       6:2:2   \n",
            "191              Flyweight       all_features             XGBoost       6:2:2   \n",
            "192      Light Heavyweight  selected_features        RandomForest       8:1:1   \n",
            "193      Light Heavyweight  selected_features  LogisticRegression       8:1:1   \n",
            "194      Light Heavyweight  selected_features                 SVM       8:1:1   \n",
            "195      Light Heavyweight  selected_features             XGBoost       8:1:1   \n",
            "196      Light Heavyweight  selected_features        RandomForest       6:3:1   \n",
            "197      Light Heavyweight  selected_features  LogisticRegression       6:3:1   \n",
            "198      Light Heavyweight  selected_features                 SVM       6:3:1   \n",
            "199      Light Heavyweight  selected_features             XGBoost       6:3:1   \n",
            "200      Light Heavyweight  selected_features        RandomForest       6:2:2   \n",
            "201      Light Heavyweight  selected_features  LogisticRegression       6:2:2   \n",
            "202      Light Heavyweight  selected_features                 SVM       6:2:2   \n",
            "203      Light Heavyweight  selected_features             XGBoost       6:2:2   \n",
            "204      Light Heavyweight       all_features        RandomForest       8:1:1   \n",
            "205      Light Heavyweight       all_features  LogisticRegression       8:1:1   \n",
            "206      Light Heavyweight       all_features                 SVM       8:1:1   \n",
            "207      Light Heavyweight       all_features             XGBoost       8:1:1   \n",
            "208      Light Heavyweight       all_features        RandomForest       6:3:1   \n",
            "209      Light Heavyweight       all_features  LogisticRegression       6:3:1   \n",
            "210      Light Heavyweight       all_features                 SVM       6:3:1   \n",
            "211      Light Heavyweight       all_features             XGBoost       6:3:1   \n",
            "212      Light Heavyweight       all_features        RandomForest       6:2:2   \n",
            "213      Light Heavyweight       all_features  LogisticRegression       6:2:2   \n",
            "214      Light Heavyweight       all_features                 SVM       6:2:2   \n",
            "215      Light Heavyweight       all_features             XGBoost       6:2:2   \n",
            "216    Women's Strawweight  selected_features        RandomForest       8:1:1   \n",
            "217    Women's Strawweight  selected_features  LogisticRegression       8:1:1   \n",
            "218    Women's Strawweight  selected_features                 SVM       8:1:1   \n",
            "219    Women's Strawweight  selected_features             XGBoost       8:1:1   \n",
            "220    Women's Strawweight  selected_features        RandomForest       6:3:1   \n",
            "221    Women's Strawweight  selected_features  LogisticRegression       6:3:1   \n",
            "222    Women's Strawweight  selected_features                 SVM       6:3:1   \n",
            "223    Women's Strawweight  selected_features             XGBoost       6:3:1   \n",
            "224    Women's Strawweight  selected_features        RandomForest       6:2:2   \n",
            "225    Women's Strawweight  selected_features  LogisticRegression       6:2:2   \n",
            "226    Women's Strawweight  selected_features                 SVM       6:2:2   \n",
            "227    Women's Strawweight  selected_features             XGBoost       6:2:2   \n",
            "228    Women's Strawweight       all_features        RandomForest       8:1:1   \n",
            "229    Women's Strawweight       all_features  LogisticRegression       8:1:1   \n",
            "230    Women's Strawweight       all_features                 SVM       8:1:1   \n",
            "231    Women's Strawweight       all_features             XGBoost       8:1:1   \n",
            "232    Women's Strawweight       all_features        RandomForest       6:3:1   \n",
            "233    Women's Strawweight       all_features  LogisticRegression       6:3:1   \n",
            "234    Women's Strawweight       all_features                 SVM       6:3:1   \n",
            "235    Women's Strawweight       all_features             XGBoost       6:3:1   \n",
            "236    Women's Strawweight       all_features        RandomForest       6:2:2   \n",
            "237    Women's Strawweight       all_features  LogisticRegression       6:2:2   \n",
            "238    Women's Strawweight       all_features                 SVM       6:2:2   \n",
            "239    Women's Strawweight       all_features             XGBoost       6:2:2   \n",
            "240           Welterweight  selected_features        RandomForest       8:1:1   \n",
            "241           Welterweight  selected_features  LogisticRegression       8:1:1   \n",
            "242           Welterweight  selected_features                 SVM       8:1:1   \n",
            "243           Welterweight  selected_features             XGBoost       8:1:1   \n",
            "244           Welterweight  selected_features        RandomForest       6:3:1   \n",
            "245           Welterweight  selected_features  LogisticRegression       6:3:1   \n",
            "246           Welterweight  selected_features                 SVM       6:3:1   \n",
            "247           Welterweight  selected_features             XGBoost       6:3:1   \n",
            "248           Welterweight  selected_features        RandomForest       6:2:2   \n",
            "249           Welterweight  selected_features  LogisticRegression       6:2:2   \n",
            "250           Welterweight  selected_features                 SVM       6:2:2   \n",
            "251           Welterweight  selected_features             XGBoost       6:2:2   \n",
            "252           Welterweight       all_features        RandomForest       8:1:1   \n",
            "253           Welterweight       all_features  LogisticRegression       8:1:1   \n",
            "254           Welterweight       all_features                 SVM       8:1:1   \n",
            "255           Welterweight       all_features             XGBoost       8:1:1   \n",
            "256           Welterweight       all_features        RandomForest       6:3:1   \n",
            "257           Welterweight       all_features  LogisticRegression       6:3:1   \n",
            "258           Welterweight       all_features                 SVM       6:3:1   \n",
            "259           Welterweight       all_features             XGBoost       6:3:1   \n",
            "260           Welterweight       all_features        RandomForest       6:2:2   \n",
            "261           Welterweight       all_features  LogisticRegression       6:2:2   \n",
            "262           Welterweight       all_features                 SVM       6:2:2   \n",
            "263           Welterweight       all_features             XGBoost       6:2:2   \n",
            "264           Catch Weight  selected_features        RandomForest       8:1:1   \n",
            "265           Catch Weight  selected_features  LogisticRegression       8:1:1   \n",
            "266           Catch Weight  selected_features                 SVM       8:1:1   \n",
            "267           Catch Weight  selected_features             XGBoost       8:1:1   \n",
            "268           Catch Weight  selected_features        RandomForest       6:3:1   \n",
            "269           Catch Weight  selected_features  LogisticRegression       6:3:1   \n",
            "270           Catch Weight  selected_features                 SVM       6:3:1   \n",
            "271           Catch Weight  selected_features             XGBoost       6:3:1   \n",
            "272           Catch Weight  selected_features        RandomForest       6:2:2   \n",
            "273           Catch Weight  selected_features  LogisticRegression       6:2:2   \n",
            "274           Catch Weight  selected_features                 SVM       6:2:2   \n",
            "275           Catch Weight  selected_features             XGBoost       6:2:2   \n",
            "276           Catch Weight       all_features        RandomForest       8:1:1   \n",
            "277           Catch Weight       all_features  LogisticRegression       8:1:1   \n",
            "278           Catch Weight       all_features                 SVM       8:1:1   \n",
            "279           Catch Weight       all_features             XGBoost       8:1:1   \n",
            "280           Catch Weight       all_features        RandomForest       6:3:1   \n",
            "281           Catch Weight       all_features  LogisticRegression       6:3:1   \n",
            "282           Catch Weight       all_features                 SVM       6:3:1   \n",
            "283           Catch Weight       all_features             XGBoost       6:3:1   \n",
            "284           Catch Weight       all_features        RandomForest       6:2:2   \n",
            "285           Catch Weight       all_features  LogisticRegression       6:2:2   \n",
            "286           Catch Weight       all_features                 SVM       6:2:2   \n",
            "287           Catch Weight       all_features             XGBoost       6:2:2   \n",
            "288  Women's Featherweight  selected_features        RandomForest       8:1:1   \n",
            "289  Women's Featherweight  selected_features  LogisticRegression       8:1:1   \n",
            "290  Women's Featherweight  selected_features                 SVM       8:1:1   \n",
            "291  Women's Featherweight  selected_features             XGBoost       8:1:1   \n",
            "292  Women's Featherweight  selected_features        RandomForest       6:3:1   \n",
            "293  Women's Featherweight  selected_features  LogisticRegression       6:3:1   \n",
            "294  Women's Featherweight  selected_features                 SVM       6:3:1   \n",
            "295  Women's Featherweight  selected_features             XGBoost       6:3:1   \n",
            "296  Women's Featherweight  selected_features        RandomForest       6:2:2   \n",
            "297  Women's Featherweight  selected_features  LogisticRegression       6:2:2   \n",
            "298  Women's Featherweight  selected_features                 SVM       6:2:2   \n",
            "299  Women's Featherweight  selected_features             XGBoost       6:2:2   \n",
            "300  Women's Featherweight       all_features        RandomForest       8:1:1   \n",
            "301  Women's Featherweight       all_features  LogisticRegression       8:1:1   \n",
            "302  Women's Featherweight       all_features                 SVM       8:1:1   \n",
            "303  Women's Featherweight       all_features             XGBoost       8:1:1   \n",
            "304  Women's Featherweight       all_features        RandomForest       6:3:1   \n",
            "305  Women's Featherweight       all_features  LogisticRegression       6:3:1   \n",
            "306  Women's Featherweight       all_features                 SVM       6:3:1   \n",
            "307  Women's Featherweight       all_features             XGBoost       6:3:1   \n",
            "308  Women's Featherweight       all_features        RandomForest       6:2:2   \n",
            "309  Women's Featherweight       all_features  LogisticRegression       6:2:2   \n",
            "310  Women's Featherweight       all_features                 SVM       6:2:2   \n",
            "311  Women's Featherweight       all_features             XGBoost       6:2:2   \n",
            "\n",
            "     Validation Accuracy  Validation F1  Test Accuracy   Test F1  \n",
            "0               0.428571       0.454545       0.521739  0.521739  \n",
            "1               0.666667       0.787879       0.434783  0.606061  \n",
            "2               0.571429       0.689655       0.347826  0.516129  \n",
            "3               0.428571       0.538462       0.478261  0.454545  \n",
            "4               0.437500       0.581395       0.434783  0.380952  \n",
            "5               0.500000       0.627907       0.478261  0.538462  \n",
            "6               0.515625       0.651685       0.652174  0.666667  \n",
            "7               0.437500       0.571429       0.391304  0.363636  \n",
            "8               0.441860       0.600000       0.431818  0.468085  \n",
            "9               0.534884       0.666667       0.454545  0.538462  \n",
            "10              0.534884       0.666667       0.568182  0.641509  \n",
            "11              0.465116       0.610169       0.386364  0.425532  \n",
            "12              0.666667       0.758621       0.652174  0.666667  \n",
            "13              0.666667       0.774194       0.739130  0.750000  \n",
            "14              0.619048       0.750000       0.478261  0.600000  \n",
            "15              0.571429       0.689655       0.652174  0.636364  \n",
            "16              0.625000       0.714286       0.652174  0.636364  \n",
            "17              0.531250       0.659091       0.695652  0.666667  \n",
            "18              0.484375       0.535211       0.434783  0.315789  \n",
            "19              0.625000       0.707317       0.652174  0.636364  \n",
            "20              0.674419       0.740741       0.590909  0.653846  \n",
            "21              0.558140       0.677966       0.590909  0.640000  \n",
            "22              0.465116       0.549020       0.477273  0.410256  \n",
            "23              0.720930       0.777778       0.545455  0.600000  \n",
            "24              0.863636       0.926829       0.970149  0.984848  \n",
            "25              0.984848       0.992366       0.985075  0.992481  \n",
            "26              0.469697       0.639175       0.522388  0.686275  \n",
            "27              0.863636       0.926829       1.000000  1.000000  \n",
            "28              0.819095       0.894118       0.985075  0.992481  \n",
            "29              0.763819       0.859701       0.910448  0.953125  \n",
            "30              0.628141       0.753333       0.567164  0.723810  \n",
            "31              0.753769       0.853731       0.955224  0.977099  \n",
            "32              0.751880       0.843602       0.969925  0.984733  \n",
            "33              0.736842       0.837209       0.864662  0.927419  \n",
            "34              0.631579       0.746114       0.593985  0.745283  \n",
            "35              0.706767       0.816901       0.902256  0.948617  \n",
            "36              0.893939       0.944000       0.940299  0.969231  \n",
            "37              0.848485       0.918033       0.940299  0.969231  \n",
            "38              0.727273       0.842105       0.776119  0.873950  \n",
            "39              0.954545       0.976744       0.925373  0.961240  \n",
            "40              0.728643       0.832298       0.850746  0.919355  \n",
            "41              0.758794       0.853659       0.761194  0.864407  \n",
            "42              0.572864       0.709898       0.507463  0.673267  \n",
            "43              0.718593       0.826087       0.820896  0.901639  \n",
            "44              0.669173       0.780000       0.849624  0.918699  \n",
            "45              0.759398       0.849057       0.759398  0.863248  \n",
            "46              0.556391       0.684492       0.556391  0.714976  \n",
            "47              0.669173       0.782178       0.819549  0.900826  \n",
            "48              0.659794       0.795031       0.744898  0.853801  \n",
            "49              1.000000       1.000000       1.000000  1.000000  \n",
            "50              0.319588       0.484375       0.295918  0.456693  \n",
            "51              0.680412       0.809816       0.755102  0.860465  \n",
            "52              0.532646       0.638298       0.585859  0.738854  \n",
            "53              0.742268       0.847251       0.929293  0.963351  \n",
            "54              0.450172       0.550562       0.404040  0.575540  \n",
            "55              0.539519       0.651042       0.595960  0.746835  \n",
            "56              0.530928       0.599119       0.561224  0.718954  \n",
            "57              0.639175       0.768212       0.938776  0.968421  \n",
            "58              0.474227       0.536364       0.403061  0.574545  \n",
            "59              0.536082       0.615385       0.571429  0.727273  \n",
            "60              0.742268       0.852071       0.795918  0.886364  \n",
            "61              0.711340       0.831325       0.816327  0.898876  \n",
            "62              0.577320       0.732026       0.540816  0.701987  \n",
            "63              0.711340       0.831325       0.714286  0.833333  \n",
            "64              0.639175       0.752941       0.757576  0.862069  \n",
            "65              0.670103       0.777778       0.787879  0.881356  \n",
            "66              0.491409       0.574713       0.565657  0.722581  \n",
            "67              0.615120       0.726829       0.767677  0.868571  \n",
            "68              0.597938       0.697674       0.739796  0.850440  \n",
            "69              0.644330       0.739623       0.755102  0.860465  \n",
            "70              0.474227       0.490000       0.545918  0.706271  \n",
            "71              0.592784       0.682731       0.714286  0.833333  \n",
            "72              0.645161       0.731707       0.571429  0.682353  \n",
            "73              0.677419       0.803922       0.666667  0.792079  \n",
            "74              0.387097       0.387097       0.412698  0.327273  \n",
            "75              0.612903       0.707317       0.571429  0.689655  \n",
            "76              0.550802       0.661290       0.539683  0.674157  \n",
            "77              0.534759       0.683636       0.619048  0.755102  \n",
            "78              0.465241       0.438202       0.555556  0.562500  \n",
            "79              0.545455       0.655870       0.619048  0.720930  \n",
            "80              0.512000       0.616352       0.584000  0.707865  \n",
            "81              0.488000       0.640449       0.624000  0.758974  \n",
            "82              0.504000       0.456140       0.472000  0.484375  \n",
            "83              0.496000       0.598726       0.632000  0.738636  \n",
            "84              0.645161       0.731707       0.714286  0.785714  \n",
            "85              0.677419       0.756098       0.777778  0.825000  \n",
            "86              0.467742       0.507463       0.476190  0.521739  \n",
            "87              0.741935       0.809524       0.761905  0.814815  \n",
            "88              0.673797       0.735931       0.746032  0.809524  \n",
            "89              0.657754       0.724138       0.793651  0.847059  \n",
            "90              0.598930       0.672489       0.634921  0.722892  \n",
            "91              0.598930       0.675325       0.714286  0.780488  \n",
            "92              0.648000       0.698630       0.736000  0.804734  \n",
            "93              0.632000       0.689189       0.752000  0.816568  \n",
            "94              0.600000       0.657534       0.616000  0.710843  \n",
            "95              0.552000       0.621622       0.704000  0.775758  \n",
            "96              0.471429       0.564706       0.507042  0.631579  \n",
            "97              0.528571       0.679612       0.676056  0.792793  \n",
            "98              0.471429       0.493151       0.591549  0.688172  \n",
            "99              0.457143       0.568182       0.492958  0.625000  \n",
            "100             0.500000       0.564315       0.478873  0.564706  \n",
            "101             0.576190       0.727829       0.647887  0.778761  \n",
            "102             0.519048       0.530233       0.507042  0.545455  \n",
            "103             0.500000       0.591440       0.521127  0.638298  \n",
            "104             0.514286       0.585366       0.475177  0.543210  \n",
            "105             0.600000       0.745455       0.588652  0.736364  \n",
            "106             0.500000       0.507042       0.531915  0.560000  \n",
            "107             0.521429       0.603550       0.489362  0.604396  \n",
            "108             0.571429       0.666667       0.647887  0.761905  \n",
            "109             0.614286       0.689655       0.676056  0.780952  \n",
            "110             0.542857       0.600000       0.535211  0.592593  \n",
            "111             0.585714       0.674157       0.647887  0.761905  \n",
            "112             0.609524       0.696296       0.535211  0.645161  \n",
            "113             0.647619       0.735714       0.661972  0.764706  \n",
            "114             0.533333       0.644928       0.591549  0.694737  \n",
            "115             0.647619       0.719697       0.563380  0.710280  \n",
            "116             0.600000       0.688889       0.581560  0.677596  \n",
            "117             0.657143       0.750000       0.645390  0.736842  \n",
            "118             0.571429       0.684211       0.524823  0.629834  \n",
            "119             0.664286       0.731429       0.588652  0.704082  \n",
            "120             0.523810       0.687500       0.671875  0.803738  \n",
            "121             0.777778       0.875000       0.835938  0.910638  \n",
            "122             0.579365       0.733668       0.664062  0.798122  \n",
            "123             0.642857       0.782609       0.765625  0.867257  \n",
            "124             0.606860       0.707269       0.609375  0.757282  \n",
            "125             0.638522       0.763385       0.781250  0.877193  \n",
            "126             0.522427       0.631365       0.609375  0.757282  \n",
            "127             0.625330       0.734082       0.750000  0.857143  \n",
            "128             0.600791       0.668852       0.614173  0.760976  \n",
            "129             0.596838       0.718232       0.751969  0.858427  \n",
            "130             0.486166       0.554795       0.602362  0.750617  \n",
            "131             0.600791       0.687307       0.712598  0.832184  \n",
            "132             0.730159       0.844037       0.796875  0.886957  \n",
            "133             0.730159       0.844037       0.843750  0.915254  \n",
            "134             0.476190       0.641304       0.625000  0.769231  \n",
            "135             0.666667       0.800000       0.710938  0.831050  \n",
            "136             0.656992       0.755639       0.679688  0.809302  \n",
            "137             0.704485       0.794118       0.804688  0.891775  \n",
            "138             0.596306       0.712946       0.648438  0.786730  \n",
            "139             0.630607       0.728682       0.726562  0.841629  \n",
            "140             0.644269       0.718750       0.681102  0.810304  \n",
            "141             0.695652       0.764526       0.763780  0.866071  \n",
            "142             0.588933       0.686747       0.629921  0.771845  \n",
            "143             0.608696       0.675410       0.700787  0.824074  \n",
            "144             0.578947       0.636364       0.571429  0.640000  \n",
            "145             0.578947       0.666667       0.619048  0.714286  \n",
            "146             0.473684       0.583333       0.666667  0.740741  \n",
            "147             0.526316       0.608696       0.571429  0.666667  \n",
            "148             0.610169       0.666667       0.550000  0.608696  \n",
            "149             0.559322       0.593750       0.650000  0.720000  \n",
            "150             0.559322       0.551724       0.650000  0.695652  \n",
            "151             0.610169       0.684932       0.550000  0.640000  \n",
            "152             0.692308       0.739130       0.500000  0.565217  \n",
            "153             0.615385       0.634146       0.550000  0.625000  \n",
            "154             0.641026       0.631579       0.525000  0.558140  \n",
            "155             0.692308       0.750000       0.500000  0.600000  \n",
            "156             0.578947       0.714286       0.809524  0.846154  \n",
            "157             0.736842       0.827586       0.714286  0.785714  \n",
            "158             0.631579       0.774194       0.666667  0.787879  \n",
            "159             0.684211       0.785714       0.714286  0.785714  \n",
            "160             0.593220       0.666667       0.800000  0.833333  \n",
            "161             0.661017       0.722222       0.850000  0.888889  \n",
            "162             0.610169       0.666667       0.800000  0.846154  \n",
            "163             0.728814       0.783784       0.800000  0.833333  \n",
            "164             0.589744       0.636364       0.700000  0.769231  \n",
            "165             0.641026       0.681818       0.775000  0.836364  \n",
            "166             0.666667       0.682927       0.650000  0.740741  \n",
            "167             0.717949       0.744186       0.775000  0.836364  \n",
            "168             0.531250       0.666667       0.303030  0.342857  \n",
            "169             0.687500       0.807692       0.606061  0.745098  \n",
            "170             0.593750       0.666667       0.545455  0.545455  \n",
            "171             0.531250       0.666667       0.484848  0.564103  \n",
            "172             0.531250       0.594595       0.500000  0.585366  \n",
            "173             0.520833       0.634921       0.441176  0.536585  \n",
            "174             0.583333       0.696970       0.500000  0.622222  \n",
            "175             0.479167       0.528302       0.470588  0.550000  \n",
            "176             0.546875       0.579710       0.500000  0.602410  \n",
            "177             0.531250       0.651163       0.469697  0.567901  \n",
            "178             0.531250       0.651163       0.590909  0.703297  \n",
            "179             0.515625       0.537313       0.439394  0.531646  \n",
            "180             0.656250       0.744186       0.636364  0.684211  \n",
            "181             0.562500       0.666667       0.818182  0.850000  \n",
            "182             0.625000       0.666667       0.666667  0.717949  \n",
            "183             0.625000       0.714286       0.666667  0.717949  \n",
            "184             0.708333       0.777778       0.676471  0.717949  \n",
            "185             0.645833       0.711864       0.764706  0.818182  \n",
            "186             0.708333       0.805556       0.705882  0.807692  \n",
            "187             0.718750       0.784000       0.617647  0.666667  \n",
            "188             0.703125       0.771084       0.696970  0.756098  \n",
            "189             0.718750       0.775000       0.636364  0.707317  \n",
            "190             0.718750       0.812500       0.696970  0.800000  \n",
            "191             0.703125       0.765432       0.681818  0.746988  \n",
            "192             0.769231       0.869565       0.757576  0.862069  \n",
            "193             0.876923       0.934426       0.924242  0.960630  \n",
            "194             0.892308       0.943089       0.924242  0.960630  \n",
            "195             0.800000       0.888889       0.848485  0.918033  \n",
            "196             0.635897       0.747331       0.761194  0.864407  \n",
            "197             0.656410       0.772881       0.865672  0.928000  \n",
            "198             0.343590       0.353535       0.268657  0.423529  \n",
            "199             0.646154       0.759582       0.761194  0.864407  \n",
            "200             0.607692       0.701754       0.727273  0.842105  \n",
            "201             0.607692       0.718232       0.810606  0.895397  \n",
            "202             0.376923       0.295652       0.272727  0.428571  \n",
            "203             0.623077       0.723164       0.727273  0.842105  \n",
            "204             0.723077       0.839286       0.803030  0.890756  \n",
            "205             0.738462       0.849558       0.787879  0.881356  \n",
            "206             0.415385       0.586957       0.393939  0.565217  \n",
            "207             0.815385       0.898305       0.787879  0.881356  \n",
            "208             0.717949       0.808362       0.776119  0.873950  \n",
            "209             0.661538       0.759124       0.686567  0.814159  \n",
            "210             0.523077       0.623482       0.552239  0.711538  \n",
            "211             0.692308       0.787234       0.746269  0.854701  \n",
            "212             0.707692       0.781609       0.757576  0.862069  \n",
            "213             0.676923       0.750000       0.659091  0.794521  \n",
            "214             0.523077       0.581081       0.537879  0.699507  \n",
            "215             0.676923       0.752941       0.734848  0.847162  \n",
            "216             0.535714       0.666667       0.600000  0.727273  \n",
            "217             0.642857       0.772727       0.500000  0.651163  \n",
            "218             0.464286       0.594595       0.566667  0.666667  \n",
            "219             0.571429       0.684211       0.600000  0.714286  \n",
            "220             0.616279       0.666667       0.633333  0.744186  \n",
            "221             0.639535       0.735043       0.533333  0.681818  \n",
            "222             0.569767       0.647619       0.500000  0.634146  \n",
            "223             0.604651       0.638298       0.600000  0.714286  \n",
            "224             0.649123       0.655172       0.593220  0.714286  \n",
            "225             0.614035       0.685714       0.610169  0.747253  \n",
            "226             0.614035       0.656250       0.491525  0.634146  \n",
            "227             0.631579       0.631579       0.576271  0.683544  \n",
            "228             0.642857       0.750000       0.533333  0.611111  \n",
            "229             0.714286       0.809524       0.700000  0.742857  \n",
            "230             0.571429       0.684211       0.633333  0.702703  \n",
            "231             0.642857       0.750000       0.500000  0.615385  \n",
            "232             0.662791       0.728972       0.600000  0.684211  \n",
            "233             0.697674       0.754717       0.666667  0.736842  \n",
            "234             0.627907       0.709091       0.666667  0.782609  \n",
            "235             0.674419       0.730769       0.500000  0.615385  \n",
            "236             0.649123       0.687500       0.644068  0.740741  \n",
            "237             0.701754       0.730159       0.677966  0.765432  \n",
            "238             0.631579       0.686567       0.644068  0.764045  \n",
            "239             0.719298       0.750000       0.542373  0.658228  \n",
            "240             0.756098       0.861111       0.709677  0.830189  \n",
            "241             0.910569       0.953191       0.903226  0.949153  \n",
            "242             0.723577       0.839623       0.758065  0.862385  \n",
            "243             0.723577       0.839623       0.741935  0.851852  \n",
            "244             0.574526       0.685371       0.632000  0.774510  \n",
            "245             0.677507       0.801997       0.904000  0.949580  \n",
            "246             0.379404       0.343840       0.168000  0.287671  \n",
            "247             0.558266       0.673347       0.584000  0.737374  \n",
            "248             0.540650       0.619529       0.637097  0.778325  \n",
            "249             0.573171       0.715447       0.895161  0.944681  \n",
            "250             0.479675       0.372549       0.173387  0.295533  \n",
            "251             0.520325       0.604027       0.608871  0.756892  \n",
            "252             0.764228       0.866359       0.709677  0.830189  \n",
            "253             0.780488       0.876712       0.814516  0.897778  \n",
            "254             0.569106       0.725389       0.612903  0.760000  \n",
            "255             0.796748       0.886878       0.733871  0.846512  \n",
            "256             0.658537       0.758621       0.784000  0.878924  \n",
            "257             0.688347       0.783427       0.824000  0.903509  \n",
            "258             0.523035       0.630252       0.552000  0.711340  \n",
            "259             0.620596       0.725490       0.744000  0.853211  \n",
            "260             0.634146       0.711538       0.745968  0.854503  \n",
            "261             0.650407       0.726115       0.794355  0.885393  \n",
            "262             0.504065       0.570423       0.556452  0.715026  \n",
            "263             0.577236       0.653333       0.725806  0.841121  \n",
            "264             0.666667       0.666667       0.571429  0.727273  \n",
            "265             0.833333       0.857143       0.571429  0.727273  \n",
            "266             0.500000       0.666667       1.000000  1.000000  \n",
            "267             0.833333       0.857143       0.571429  0.727273  \n",
            "268             0.631579       0.720000       0.571429  0.727273  \n",
            "269             0.684211       0.727273       0.571429  0.727273  \n",
            "270             0.631579       0.774194       1.000000  1.000000  \n",
            "271             0.578947       0.666667       0.857143  0.923077  \n",
            "272             0.583333       0.705882       0.642857  0.736842  \n",
            "273             0.500000       0.571429       0.785714  0.842105  \n",
            "274             0.666667       0.800000       0.785714  0.880000  \n",
            "275             0.500000       0.625000       0.785714  0.857143  \n",
            "276             0.333333       0.333333       0.714286  0.833333  \n",
            "277             1.000000       1.000000       0.714286  0.833333  \n",
            "278             0.500000       0.666667       1.000000  1.000000  \n",
            "279             0.333333       0.333333       0.857143  0.923077  \n",
            "280             0.736842       0.800000       0.714286  0.833333  \n",
            "281             0.789474       0.833333       0.714286  0.833333  \n",
            "282             0.631579       0.774194       1.000000  1.000000  \n",
            "283             0.631579       0.666667       0.857143  0.923077  \n",
            "284             0.916667       0.941176       0.571429  0.700000  \n",
            "285             0.750000       0.823529       0.785714  0.842105  \n",
            "286             0.666667       0.800000       0.785714  0.880000  \n",
            "287             0.750000       0.800000       0.642857  0.736842  \n",
            "288             0.000000       0.000000       0.333333  0.500000  \n",
            "289             0.500000       0.666667       0.333333  0.500000  \n",
            "290             0.500000       0.666667       0.333333  0.500000  \n",
            "291             0.500000       0.666667       0.333333  0.500000  \n",
            "292             0.333333       0.333333       0.333333  0.500000  \n",
            "293             0.333333       0.000000       0.333333  0.500000  \n",
            "294             0.666667       0.800000       0.333333  0.500000  \n",
            "295             0.666667       0.800000       0.333333  0.500000  \n",
            "296             0.500000       0.500000       0.200000  0.333333  \n",
            "297             0.250000       0.000000       0.400000  0.400000  \n",
            "298             0.750000       0.857143       0.400000  0.571429  \n",
            "299             0.750000       0.857143       0.400000  0.571429  \n",
            "300             0.500000       0.666667       0.333333  0.500000  \n",
            "301             0.500000       0.666667       0.333333  0.000000  \n",
            "302             0.500000       0.666667       0.333333  0.500000  \n",
            "303             0.500000       0.666667       0.333333  0.500000  \n",
            "304             0.833333       0.888889       0.333333  0.500000  \n",
            "305             0.666667       0.750000       0.666667  0.666667  \n",
            "306             0.666667       0.800000       0.333333  0.500000  \n",
            "307             0.666667       0.750000       0.333333  0.500000  \n",
            "308             1.000000       1.000000       0.400000  0.571429  \n",
            "309             0.750000       0.800000       0.600000  0.666667  \n",
            "310             0.750000       0.857143       0.400000  0.571429  \n",
            "311             0.750000       0.800000       0.400000  0.571429  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vrfo_6JW7t5a"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}